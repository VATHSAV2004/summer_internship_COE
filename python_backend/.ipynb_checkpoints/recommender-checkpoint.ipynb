{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8bcc7cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University Name</th>\n",
       "      <th>Student Name</th>\n",
       "      <th>Project Title</th>\n",
       "      <th>Project Description</th>\n",
       "      <th>Project Category/Field</th>\n",
       "      <th>Project Supervisor/Advisor</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Keywords/Tags</th>\n",
       "      <th>GitHub Repository URL</th>\n",
       "      <th>Tools/Technologies Used</th>\n",
       "      <th>Project Outcome/Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Institute</td>\n",
       "      <td>Daniel Kim</td>\n",
       "      <td>Fraud Detection System using Machine Learning</td>\n",
       "      <td>The project aims to develop a fraud detection ...</td>\n",
       "      <td>Finance, Machine Learning</td>\n",
       "      <td>Prof. Jessica Wong</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>Fraud Detection, Anomaly Detection, Transactio...</td>\n",
       "      <td>https://github.com/danielkim/fraud-detection-s...</td>\n",
       "      <td>Python, scikit-learn, Pandas</td>\n",
       "      <td>Achieved 98% accuracy in detecting fraudulent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI Robotics Research Center</td>\n",
       "      <td>Emily Liu</td>\n",
       "      <td>Humanoid Robot for Assisting Elderly People</td>\n",
       "      <td>The project aims to develop an advanced roboti...</td>\n",
       "      <td>Robotics, Artificial Intelligence</td>\n",
       "      <td>Dr. David Chen</td>\n",
       "      <td>2023-07-15</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>Humanoid Robot, Elderly Care, Natural Language...</td>\n",
       "      <td>https://github.com/emilyliu/humanoid-robot-ass...</td>\n",
       "      <td>ROS, TensorFlow, OpenCV</td>\n",
       "      <td>Achieved human-like interactions with elderly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Learning Lab</td>\n",
       "      <td>Jason Wang</td>\n",
       "      <td>Autonomous Vehicle Navigation using Deep Reinf...</td>\n",
       "      <td>The project focuses on developing deep reinfor...</td>\n",
       "      <td>Autonomous Vehicles, Deep Learning</td>\n",
       "      <td>Dr. Sarah Zhang</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>Autonomous Vehicles, Deep Reinforcement Learni...</td>\n",
       "      <td>https://github.com/jasonwang/autonomous-vehicl...</td>\n",
       "      <td>Python, TensorFlow, OpenAI Gym</td>\n",
       "      <td>Achieved safe and efficient navigation in vari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Computer Vision Research Group</td>\n",
       "      <td>Sophia Chen</td>\n",
       "      <td>Semantic Segmentation for Medical Image Analysis</td>\n",
       "      <td>The project aims to develop a semantic segment...</td>\n",
       "      <td>Medical Imaging, Computer Vision</td>\n",
       "      <td>Prof. Michael Li</td>\n",
       "      <td>2023-09-15</td>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>Semantic Segmentation, Medical Imaging, Deep L...</td>\n",
       "      <td>https://github.com/sophiachen/medical-image-se...</td>\n",
       "      <td>Python, TensorFlow, PyTorch</td>\n",
       "      <td>Achieved state-of-the-art performance in seman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natural Language Processing Lab</td>\n",
       "      <td>Ryan Patel</td>\n",
       "      <td>Emotion Recognition from Text using Deep Learning</td>\n",
       "      <td>The project aims to develop a deep learning-ba...</td>\n",
       "      <td>Natural Language Processing, Deep Learning</td>\n",
       "      <td>Dr. Michelle Chen</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Emotion Recognition, Sentiment Analysis, Text ...</td>\n",
       "      <td>https://github.com/ryanpatel/emotion-recognition</td>\n",
       "      <td>Python, TensorFlow, PyTorch, NLTK</td>\n",
       "      <td>Achieved state-of-the-art performance in emoti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   University Name Student Name  \\\n",
       "0           Data Science Institute   Daniel Kim   \n",
       "1      AI Robotics Research Center    Emily Liu   \n",
       "2             Machine Learning Lab   Jason Wang   \n",
       "3   Computer Vision Research Group  Sophia Chen   \n",
       "4  Natural Language Processing Lab   Ryan Patel   \n",
       "\n",
       "                                       Project Title  \\\n",
       "0      Fraud Detection System using Machine Learning   \n",
       "1        Humanoid Robot for Assisting Elderly People   \n",
       "2  Autonomous Vehicle Navigation using Deep Reinf...   \n",
       "3   Semantic Segmentation for Medical Image Analysis   \n",
       "4  Emotion Recognition from Text using Deep Learning   \n",
       "\n",
       "                                 Project Description  \\\n",
       "0  The project aims to develop a fraud detection ...   \n",
       "1  The project aims to develop an advanced roboti...   \n",
       "2  The project focuses on developing deep reinfor...   \n",
       "3  The project aims to develop a semantic segment...   \n",
       "4  The project aims to develop a deep learning-ba...   \n",
       "\n",
       "                       Project Category/Field Project Supervisor/Advisor  \\\n",
       "0                   Finance, Machine Learning         Prof. Jessica Wong   \n",
       "1           Robotics, Artificial Intelligence             Dr. David Chen   \n",
       "2          Autonomous Vehicles, Deep Learning            Dr. Sarah Zhang   \n",
       "3            Medical Imaging, Computer Vision           Prof. Michael Li   \n",
       "4  Natural Language Processing, Deep Learning          Dr. Michelle Chen   \n",
       "\n",
       "   Start Date    End Date                                      Keywords/Tags  \\\n",
       "0  2023-06-01  2024-03-01  Fraud Detection, Anomaly Detection, Transactio...   \n",
       "1  2023-07-15  2024-04-15  Humanoid Robot, Elderly Care, Natural Language...   \n",
       "2  2023-08-01  2024-05-01  Autonomous Vehicles, Deep Reinforcement Learni...   \n",
       "3  2023-09-15  2024-06-15  Semantic Segmentation, Medical Imaging, Deep L...   \n",
       "4  2023-10-01  2024-07-01  Emotion Recognition, Sentiment Analysis, Text ...   \n",
       "\n",
       "                               GitHub Repository URL  \\\n",
       "0  https://github.com/danielkim/fraud-detection-s...   \n",
       "1  https://github.com/emilyliu/humanoid-robot-ass...   \n",
       "2  https://github.com/jasonwang/autonomous-vehicl...   \n",
       "3  https://github.com/sophiachen/medical-image-se...   \n",
       "4   https://github.com/ryanpatel/emotion-recognition   \n",
       "\n",
       "             Tools/Technologies Used  \\\n",
       "0       Python, scikit-learn, Pandas   \n",
       "1            ROS, TensorFlow, OpenCV   \n",
       "2     Python, TensorFlow, OpenAI Gym   \n",
       "3        Python, TensorFlow, PyTorch   \n",
       "4  Python, TensorFlow, PyTorch, NLTK   \n",
       "\n",
       "                          Project Outcome/Evaluation  \n",
       "0  Achieved 98% accuracy in detecting fraudulent ...  \n",
       "1  Achieved human-like interactions with elderly ...  \n",
       "2  Achieved safe and efficient navigation in vari...  \n",
       "3  Achieved state-of-the-art performance in seman...  \n",
       "4  Achieved state-of-the-art performance in emoti...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "projects=pd.read_csv(\"output.csv\")\n",
    "projects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "11028959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project Title</th>\n",
       "      <th>Project Description</th>\n",
       "      <th>Project Category/Field</th>\n",
       "      <th>Keywords/Tags</th>\n",
       "      <th>Tools/Technologies Used</th>\n",
       "      <th>Project Outcome/Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fraud Detection System using Machine Learning</td>\n",
       "      <td>The project aims to develop a fraud detection ...</td>\n",
       "      <td>Finance, Machine Learning</td>\n",
       "      <td>Fraud Detection, Anomaly Detection, Transactio...</td>\n",
       "      <td>Python, scikit-learn, Pandas</td>\n",
       "      <td>Achieved 98% accuracy in detecting fraudulent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Humanoid Robot for Assisting Elderly People</td>\n",
       "      <td>The project aims to develop an advanced roboti...</td>\n",
       "      <td>Robotics, Artificial Intelligence</td>\n",
       "      <td>Humanoid Robot, Elderly Care, Natural Language...</td>\n",
       "      <td>ROS, TensorFlow, OpenCV</td>\n",
       "      <td>Achieved human-like interactions with elderly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autonomous Vehicle Navigation using Deep Reinf...</td>\n",
       "      <td>The project focuses on developing deep reinfor...</td>\n",
       "      <td>Autonomous Vehicles, Deep Learning</td>\n",
       "      <td>Autonomous Vehicles, Deep Reinforcement Learni...</td>\n",
       "      <td>Python, TensorFlow, OpenAI Gym</td>\n",
       "      <td>Achieved safe and efficient navigation in vari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semantic Segmentation for Medical Image Analysis</td>\n",
       "      <td>The project aims to develop a semantic segment...</td>\n",
       "      <td>Medical Imaging, Computer Vision</td>\n",
       "      <td>Semantic Segmentation, Medical Imaging, Deep L...</td>\n",
       "      <td>Python, TensorFlow, PyTorch</td>\n",
       "      <td>Achieved state-of-the-art performance in seman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emotion Recognition from Text using Deep Learning</td>\n",
       "      <td>The project aims to develop a deep learning-ba...</td>\n",
       "      <td>Natural Language Processing, Deep Learning</td>\n",
       "      <td>Emotion Recognition, Sentiment Analysis, Text ...</td>\n",
       "      <td>Python, TensorFlow, PyTorch, NLTK</td>\n",
       "      <td>Achieved state-of-the-art performance in emoti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Project Title  \\\n",
       "0      Fraud Detection System using Machine Learning   \n",
       "1        Humanoid Robot for Assisting Elderly People   \n",
       "2  Autonomous Vehicle Navigation using Deep Reinf...   \n",
       "3   Semantic Segmentation for Medical Image Analysis   \n",
       "4  Emotion Recognition from Text using Deep Learning   \n",
       "\n",
       "                                 Project Description  \\\n",
       "0  The project aims to develop a fraud detection ...   \n",
       "1  The project aims to develop an advanced roboti...   \n",
       "2  The project focuses on developing deep reinfor...   \n",
       "3  The project aims to develop a semantic segment...   \n",
       "4  The project aims to develop a deep learning-ba...   \n",
       "\n",
       "                       Project Category/Field  \\\n",
       "0                   Finance, Machine Learning   \n",
       "1           Robotics, Artificial Intelligence   \n",
       "2          Autonomous Vehicles, Deep Learning   \n",
       "3            Medical Imaging, Computer Vision   \n",
       "4  Natural Language Processing, Deep Learning   \n",
       "\n",
       "                                       Keywords/Tags  \\\n",
       "0  Fraud Detection, Anomaly Detection, Transactio...   \n",
       "1  Humanoid Robot, Elderly Care, Natural Language...   \n",
       "2  Autonomous Vehicles, Deep Reinforcement Learni...   \n",
       "3  Semantic Segmentation, Medical Imaging, Deep L...   \n",
       "4  Emotion Recognition, Sentiment Analysis, Text ...   \n",
       "\n",
       "             Tools/Technologies Used  \\\n",
       "0       Python, scikit-learn, Pandas   \n",
       "1            ROS, TensorFlow, OpenCV   \n",
       "2     Python, TensorFlow, OpenAI Gym   \n",
       "3        Python, TensorFlow, PyTorch   \n",
       "4  Python, TensorFlow, PyTorch, NLTK   \n",
       "\n",
       "                          Project Outcome/Evaluation  \n",
       "0  Achieved 98% accuracy in detecting fraudulent ...  \n",
       "1  Achieved human-like interactions with elderly ...  \n",
       "2  Achieved safe and efficient navigation in vari...  \n",
       "3  Achieved state-of-the-art performance in seman...  \n",
       "4  Achieved state-of-the-art performance in emoti...  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects=projects[[\"Project Title\",\"Project Description\",\"Project Category/Field\",\"Keywords/Tags\",\"Tools/Technologies Used\",\"Project Outcome/Evaluation\"]]\n",
    "projects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c0804ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "132     True\n",
       "133     True\n",
       "134     True\n",
       "135     True\n",
       "136     True\n",
       "Length: 137, dtype: bool"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4b1c4057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "136ce52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects=projects.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e0b8d002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "126    False\n",
       "127    False\n",
       "128    False\n",
       "129    False\n",
       "130    False\n",
       "Length: 131, dtype: bool"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1b7df627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bb6b056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects['tags']=projects['Project Description']+projects['Project Category/Field']+projects['Keywords/Tags']+projects['Tools/Technologies Used']+projects['Project Outcome/Evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dba5aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=projects[['Project Title','tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9647ce80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project Title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fraud Detection System using Machine Learning</td>\n",
       "      <td>The project aims to develop a fraud detection ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Humanoid Robot for Assisting Elderly People</td>\n",
       "      <td>The project aims to develop an advanced roboti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autonomous Vehicle Navigation using Deep Reinf...</td>\n",
       "      <td>The project focuses on developing deep reinfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semantic Segmentation for Medical Image Analysis</td>\n",
       "      <td>The project aims to develop a semantic segment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emotion Recognition from Text using Deep Learning</td>\n",
       "      <td>The project aims to develop a deep learning-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Reinforcement Learning for Robot Manipulation</td>\n",
       "      <td>This project focuses on reinforcement learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Time Series Forecasting for Energy Demand Pred...</td>\n",
       "      <td>This project focuses on time series forecastin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Object Detection and Recognition for Autonomou...</td>\n",
       "      <td>This project focuses on object detection and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Question Answering Systems for Biomedical Lite...</td>\n",
       "      <td>This project focuses on developing question an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Gesture Recognition for Human-Robot Interaction</td>\n",
       "      <td>This project focuses on gesture recognition te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Project Title  \\\n",
       "0        Fraud Detection System using Machine Learning   \n",
       "1          Humanoid Robot for Assisting Elderly People   \n",
       "2    Autonomous Vehicle Navigation using Deep Reinf...   \n",
       "3     Semantic Segmentation for Medical Image Analysis   \n",
       "4    Emotion Recognition from Text using Deep Learning   \n",
       "..                                                 ...   \n",
       "126      Reinforcement Learning for Robot Manipulation   \n",
       "127  Time Series Forecasting for Energy Demand Pred...   \n",
       "128  Object Detection and Recognition for Autonomou...   \n",
       "129  Question Answering Systems for Biomedical Lite...   \n",
       "130    Gesture Recognition for Human-Robot Interaction   \n",
       "\n",
       "                                                  tags  \n",
       "0    The project aims to develop a fraud detection ...  \n",
       "1    The project aims to develop an advanced roboti...  \n",
       "2    The project focuses on developing deep reinfor...  \n",
       "3    The project aims to develop a semantic segment...  \n",
       "4    The project aims to develop a deep learning-ba...  \n",
       "..                                                 ...  \n",
       "126  This project focuses on reinforcement learning...  \n",
       "127  This project focuses on time series forecastin...  \n",
       "128  This project focuses on object detection and r...  \n",
       "129  This project focuses on developing question an...  \n",
       "130  This project focuses on gesture recognition te...  \n",
       "\n",
       "[131 rows x 2 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "87d4ec91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fraud Detection System using Machine Learning</td>\n",
       "      <td>The project aims to develop a fraud detection ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Humanoid Robot for Assisting Elderly People</td>\n",
       "      <td>The project aims to develop an advanced roboti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Autonomous Vehicle Navigation using Deep Reinf...</td>\n",
       "      <td>The project focuses on developing deep reinfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Semantic Segmentation for Medical Image Analysis</td>\n",
       "      <td>The project aims to develop a semantic segment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Emotion Recognition from Text using Deep Learning</td>\n",
       "      <td>The project aims to develop a deep learning-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>127</td>\n",
       "      <td>Reinforcement Learning for Robot Manipulation</td>\n",
       "      <td>This project focuses on reinforcement learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>Time Series Forecasting for Energy Demand Pred...</td>\n",
       "      <td>This project focuses on time series forecastin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129</td>\n",
       "      <td>Object Detection and Recognition for Autonomou...</td>\n",
       "      <td>This project focuses on object detection and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>130</td>\n",
       "      <td>Question Answering Systems for Biomedical Lite...</td>\n",
       "      <td>This project focuses on developing question an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>131</td>\n",
       "      <td>Gesture Recognition for Human-Robot Interaction</td>\n",
       "      <td>This project focuses on gesture recognition te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     project_id                                              title  \\\n",
       "0             1      Fraud Detection System using Machine Learning   \n",
       "1             2        Humanoid Robot for Assisting Elderly People   \n",
       "2             3  Autonomous Vehicle Navigation using Deep Reinf...   \n",
       "3             4   Semantic Segmentation for Medical Image Analysis   \n",
       "4             5  Emotion Recognition from Text using Deep Learning   \n",
       "..          ...                                                ...   \n",
       "126         127      Reinforcement Learning for Robot Manipulation   \n",
       "127         128  Time Series Forecasting for Energy Demand Pred...   \n",
       "128         129  Object Detection and Recognition for Autonomou...   \n",
       "129         130  Question Answering Systems for Biomedical Lite...   \n",
       "130         131    Gesture Recognition for Human-Robot Interaction   \n",
       "\n",
       "                                                  tags  \n",
       "0    The project aims to develop a fraud detection ...  \n",
       "1    The project aims to develop an advanced roboti...  \n",
       "2    The project focuses on developing deep reinfor...  \n",
       "3    The project aims to develop a semantic segment...  \n",
       "4    The project aims to develop a deep learning-ba...  \n",
       "..                                                 ...  \n",
       "126  This project focuses on reinforcement learning...  \n",
       "127  This project focuses on time series forecastin...  \n",
       "128  This project focuses on object detection and r...  \n",
       "129  This project focuses on developing question an...  \n",
       "130  This project focuses on gesture recognition te...  \n",
       "\n",
       "[131 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects['project_id'] = range(1, len(projects) + 1)\n",
    "projects['title']=projects['Project Title']\n",
    "new_df = projects[['project_id', 'title', 'tags']]\n",
    "new_df = new_df[['project_id', 'title', 'tags']]\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "63179975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all to lower string\n",
    "new_df['tags']=new_df['tags'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3417ee53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fraud Detection System using Machine Learning</td>\n",
       "      <td>the project aims to develop a fraud detection ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Humanoid Robot for Assisting Elderly People</td>\n",
       "      <td>the project aims to develop an advanced roboti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Autonomous Vehicle Navigation using Deep Reinf...</td>\n",
       "      <td>the project focuses on developing deep reinfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Semantic Segmentation for Medical Image Analysis</td>\n",
       "      <td>the project aims to develop a semantic segment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Emotion Recognition from Text using Deep Learning</td>\n",
       "      <td>the project aims to develop a deep learning-ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   project_id                                              title  \\\n",
       "0           1      Fraud Detection System using Machine Learning   \n",
       "1           2        Humanoid Robot for Assisting Elderly People   \n",
       "2           3  Autonomous Vehicle Navigation using Deep Reinf...   \n",
       "3           4   Semantic Segmentation for Medical Image Analysis   \n",
       "4           5  Emotion Recognition from Text using Deep Learning   \n",
       "\n",
       "                                                tags  \n",
       "0  the project aims to develop a fraud detection ...  \n",
       "1  the project aims to develop an advanced roboti...  \n",
       "2  the project focuses on developing deep reinfor...  \n",
       "3  the project aims to develop a semantic segment...  \n",
       "4  the project aims to develop a deep learning-ba...  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4fa06b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The term \"scikit\" in \"scikit-learn\" is derived from the word \"SciKit,\" where \"Sci\" stands for science or scientific, and \"Kit\" refers to a collection of tools or a toolkit. In the context of scikit-learn, it essentially means a scientific toolkit for machine learning in Python.\n",
    "#CountVectorizer is a class in scikit-learn, specifically in the sklearn.feature_extraction.text module. It is used for converting a collection of text documents to a matrix of token counts.\n",
    "#Here's a brief overview of how CountVectorizer works:\n",
    "#Tokenization: It tokenizes the input text, which means breaking down the text into individual words or terms (tokens).\n",
    "#Counting: It counts the occurrences of each token in each document.\n",
    "#Vectorization: It represents each document as a vector, where each element of the vector corresponds to the count of a particular token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8d25024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before that we have to do stemming\n",
    "#stemming ['loveed','loving','love']====>['love','love','love']\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8dcae20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    list=[]\n",
    "    for i in text.split():\n",
    "        list.append(ps.stem(i))\n",
    "    return \" \".join(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d87df130",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['tags']=new_df['tags'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "92c9f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words removes stopwords\n",
    "#max_features says how many words to select\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(max_features=2000,stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "478b2744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The toarray() method is used after fit_transform when working with sparse matrices in scikit-learn. Many text-related transformations, such as those performed by CountVectorizer or TfidfVectorizer, result in sparse matrices by default. Sparse matrices are a memory-efficient way to represent matrices that are mostly composed of zeros.\n",
    "#Sparse Matrices:In natural language processing (NLP), especially when dealing with large text corpora, the term-document matrix can be very large and sparse (most entries are zero). Representing such matrices in a dense form (using a regular NumPy array) would be memory-inefficient.\n",
    "#Memory Efficiency:The fit_transform method, when used with text transformers, often returns a sparse matrix by default to save memory. A sparse matrix only stores non-zero elements and their positions, which can be much more memory-efficient when dealing with large datasets.\n",
    "#The fit_transform method in scikit-learn is commonly used for two purposes:Fit:Learning from Data: During the \"fit\" step, the transformer (in this case, CountVectorizer) analyzes the input data to learn any necessary parameters. For CountVectorizer, this involves learning the vocabulary (unique words) from the training data.Transform:\n",
    "#Applying the Transformation: The \"transform\" step applies the learned parameters to the input data, producing the transformed output. In the case of CountVectorizer, it converts a collection of text documents into a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b7a02977",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=cv.fit_transform(new_df['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b460f18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a3218637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2d', '3d', 'ab', ..., 'yolo', 'zero', 'zk'], dtype=object)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv method get_feature_names gives the most common 5000 words\n",
    "cv.get_feature_names_out()\n",
    "#In scikit-learn versions 0.22.0 and later, get_feature_names is available as get_feature_names_out. The name of the method was changed in the later versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "54cc473c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2d', '3d', 'ab', 'abil', 'abilities', 'abnorm', 'absolut',\n",
       "       'abstract', 'acceler', 'acceleration', 'accept', 'access',\n",
       "       'accord', 'account', 'accur', 'accuraci', 'accuracy', 'accurately',\n",
       "       'achiev', 'acid', 'acoust', 'acquir', 'acquisit', 'acquisition',\n",
       "       'act', 'action', 'actions', 'activ', 'activities', 'activity',\n",
       "       'actor', 'actuat', 'ad', 'adam', 'adapt', 'adaptation', 'add',\n",
       "       'addit', 'address', 'adhd', 'adher', 'adjust', 'adjustment',\n",
       "       'admet', 'administr', 'admissions', 'adopt', 'advanc', 'advantag',\n",
       "       'advers', 'adversari', 'adversaries', 'aerial', 'aerodynam',\n",
       "       'aerospac', 'affect', 'affin', 'ag', 'agencies', 'agent', 'agents',\n",
       "       'aggreg', 'aggregation', 'agi', 'agil', 'agnost', 'agreement',\n",
       "       'ai', 'aim', 'air', 'alarm', 'alert', 'alerting', 'alerts',\n",
       "       'algorithm', 'algorithms', 'align', 'alignment', 'allel', 'alloc',\n",
       "       'allocation', 'allow', 'amino', 'amm', 'amr', 'analys', 'analyses',\n",
       "       'analysi', 'analysis', 'analysissenti', 'analyst', 'analyt',\n",
       "       'analytics', 'analyticspython', 'analyz', 'analyze', 'anatom',\n",
       "       'anger', 'ani', 'anim', 'animation', 'annot', 'annotation',\n",
       "       'annotations', 'anomal', 'anomali', 'anomalies', 'anonym',\n",
       "       'answer', 'antibiot', 'anticip', 'antimicrobi', 'apach', 'api',\n",
       "       'apis', 'appear', 'appearance', 'appli', 'applic', 'applications',\n",
       "       'approach', 'approaches', 'appropri', 'approxim', 'ar',\n",
       "       'architectur', 'architecture', 'architectures', 'area', 'areas',\n",
       "       'arima', 'art', 'articles', 'artifact', 'artifacts', 'artifici',\n",
       "       'artist', 'asd', 'aspect', 'aspects', 'assays', 'assembl',\n",
       "       'assert', 'assess', 'assessment', 'assessments', 'asset', 'assets',\n",
       "       'assign', 'assignment', 'assist', 'assistance', 'assistants',\n",
       "       'associ', 'atmospher', 'attack', 'attacks', 'attacksadversari',\n",
       "       'attempts', 'attend', 'attent', 'attention', 'attitudes',\n",
       "       'attribut', 'attributes', 'attribution', 'auc', 'auction', 'audio',\n",
       "       'audit', 'augment', 'augmentation', 'authent', 'authentication',\n",
       "       'author', 'authorities', 'autism', 'autoencod', 'autoencoders',\n",
       "       'autom', 'automat', 'automation', 'automationdialogu', 'autonom',\n",
       "       'autonomi', 'autonomously', 'autoregress', 'availability',\n",
       "       'averag', 'avoid', 'avoidance', 'awar', 'awareness', 'backbon',\n",
       "       'backend', 'background', 'bacteri', 'bag', 'balanc', 'bandwidth',\n",
       "       'bas', 'base', 'bases', 'batch', 'bayesian', 'bci', 'bcis',\n",
       "       'befor', 'behavior', 'behaviors', 'benchmark', 'benchmarking',\n",
       "       'benchmarks', 'benefit', 'benign', 'bert', 'best', 'bia', 'bias',\n",
       "       'bidirect', 'bilingu', 'binanc', 'binari', 'bind', 'biobert',\n",
       "       'biochem', 'bioinformat', 'bioinformatics', 'biolog', 'biology',\n",
       "       'biomark', 'biomarkers', 'biomed', 'biopythonfocus', 'black',\n",
       "       'bleu', 'blockchain', 'blockchainsolidity', 'bodi', 'boltzmann',\n",
       "       'boost', 'boosting', 'bootstrapping', 'borrow', 'borrowing',\n",
       "       'bound', 'boundari', 'boundaries', 'bow', 'box', 'brain', 'brand',\n",
       "       'breach', 'brush', 'build', 'buildings', 'busi', 'calibr',\n",
       "       'calibration', 'calling', 'camera', 'cameras', 'candid',\n",
       "       'capabilities', 'capabl', 'captur', 'care', 'carlini', 'carlo',\n",
       "       'case', 'cases', 'categori', 'categories', 'caus', 'cdss',\n",
       "       'cellular', 'cent', 'centr', 'central', 'chain', 'challeng',\n",
       "       'chang', 'change', 'changes', 'channel', 'character',\n",
       "       'characterist', 'characteristics', 'charts', 'chat', 'chatbot',\n",
       "       'chatbots', 'chemic', 'children', 'chronic', 'circuit', 'citizen',\n",
       "       'class', 'classic', 'classif', 'classifi', 'classification',\n",
       "       'classifiers', 'clean', 'cleaning', 'climat', 'clinic',\n",
       "       'clinician', 'clinicians', 'closed', 'closur', 'cloud', 'clouds',\n",
       "       'cluster', 'clustering', 'clutter', 'cnn', 'cnns', 'code', 'codes',\n",
       "       'coefficient', 'cognit', 'coher', 'coherence', 'cohort',\n",
       "       'collabor', 'collaboration', 'collater', 'collect', 'collection',\n",
       "       'collis', 'collision', 'collisions', 'color', 'combin', 'comfort',\n",
       "       'command', 'commands', 'comments', 'common', 'commun',\n",
       "       'communication', 'communities', 'community', 'compar', 'compil',\n",
       "       'complementari', 'complet', 'completion', 'complex', 'complexity',\n",
       "       'complianc', 'compon', 'components', 'composition', 'compound',\n",
       "       'comprehens', 'compromis', 'comput', 'computation', 'computing',\n",
       "       'concept', 'concepts', 'concis', 'condit', 'conditions', 'conduct',\n",
       "       'confid', 'confidenti', 'confidentiality', 'configur', 'congest',\n",
       "       'connect', 'connections', 'consciou', 'conscious', 'consensu',\n",
       "       'conserv', 'consid', 'consist', 'consistency', 'constrain',\n",
       "       'constraint', 'constraints', 'construct', 'consumpt',\n",
       "       'consumption', 'contain', 'content', 'context', 'contextu',\n",
       "       'continu', 'contract', 'contracts', 'contrast', 'contribut',\n",
       "       'control', 'controllers', 'converg', 'convers', 'conversations',\n",
       "       'convey', 'convolut', 'cooper', 'coordin', 'coordination',\n",
       "       'corpora', 'corpu', 'correct', 'correction', 'correl',\n",
       "       'correspond', 'countermeasur', 'cover', 'coverag', 'cp', 'craft',\n",
       "       'creat', 'creativ', 'credenti', 'crit', 'criteria', 'cross',\n",
       "       'cryptograph', 'cryptography', 'ct', 'cue', 'cues', 'current',\n",
       "       'curriculum', 'curv', 'custom', 'customers', 'cyber', 'cybersecur',\n",
       "       'cybersecurity', 'cybersecuritypython', 'cyclists', 'daili',\n",
       "       'dashboard', 'dashboards', 'data', 'databas', 'databases',\n",
       "       'dataset', 'datasets', 'decentr', 'decis', 'decision', 'decisions',\n",
       "       'decod', 'decomposit', 'deep', 'deeplab', 'defens', 'defense',\n",
       "       'defenses', 'defi', 'defin', 'deletions', 'delin', 'deliveri',\n",
       "       'delivery', 'demand', 'demograph', 'demographics', 'demonstr',\n",
       "       'deni', 'denoising', 'dens', 'depend', 'deploy', 'deployment',\n",
       "       'depth', 'deriv', 'descent', 'descriptor', 'design', 'desir',\n",
       "       'detect', 'detection', 'detector', 'determin', 'develop',\n",
       "       'development', 'deviat', 'devic', 'devices', 'dex', 'diagnosi',\n",
       "       'diagnosis', 'diagnost', 'dialog', 'dialogu', 'dice', 'differ',\n",
       "       'differenti', 'digit', 'dimension', 'direct'], dtype=object)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "71c43c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b1604629",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity=cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "26e826aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131, 131)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2a64fbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.25185312, 0.29713433, 0.28966445, 0.48417292,\n",
       "       0.48893053, 0.3233768 , 0.16317757, 0.22914873, 0.11821975,\n",
       "       0.19577891, 0.18109008, 0.12132135, 0.28164077, 0.36675858,\n",
       "       0.34751844, 0.43255199, 0.07946413, 0.17643737, 0.23676941,\n",
       "       0.20385147, 0.44565947, 0.29531321, 0.37549653, 0.40378692,\n",
       "       0.11025972, 0.38177475, 0.22595321, 0.23854758, 0.16967816,\n",
       "       0.3603758 , 0.24529683, 0.23147498, 0.15092844, 0.49483508,\n",
       "       0.22697652, 0.25457919, 0.27141334, 0.40212916, 0.18454128,\n",
       "       0.20054492, 0.18888463, 0.22151696, 0.11857711, 0.22710073,\n",
       "       0.22642542, 0.3460908 , 0.22866193, 0.21547727, 0.20916733,\n",
       "       0.44362237, 0.37579961, 0.20124541, 0.17587552, 0.08948379,\n",
       "       0.21530615, 0.20373699, 0.36339102, 0.30720694, 0.24778144,\n",
       "       0.35398416, 0.32540223, 0.4738907 , 0.16204449, 0.26720838,\n",
       "       0.52803886, 0.20675595, 0.19130553, 0.0914837 , 0.1525679 ,\n",
       "       0.22562854, 0.14452928, 0.20080868, 0.12014675, 0.44504632,\n",
       "       0.46448577, 0.17606919, 0.24297933, 0.15337433, 0.08689354,\n",
       "       0.11952192, 0.23897855, 0.27019496, 0.2590176 , 0.12306704,\n",
       "       0.15054546, 0.08675939, 0.52164316, 0.10311744, 0.23280062,\n",
       "       0.19306225, 0.35525889, 0.10843608, 0.14070238, 0.25192647,\n",
       "       0.23686085, 0.16120364, 0.12629954, 0.18233294, 0.28520126,\n",
       "       0.18275025, 0.06512539, 0.21389932, 0.30695158, 0.29779328,\n",
       "       0.18900664, 0.30144956, 0.40407701, 0.16614773, 0.44611452,\n",
       "       0.29890009, 0.37450966, 0.18911509, 0.30353216, 0.15358955,\n",
       "       0.41667468, 0.2534618 , 0.21894785, 0.44565735, 0.36478245,\n",
       "       0.07136709, 0.15182188, 0.23509307, 0.20215428, 0.32671466,\n",
       "       0.2276845 , 0.17658996, 0.43613028, 0.20812721, 0.13198381,\n",
       "       0.18826924])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1db71a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enumerate at 0x1f4d96661c0>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=enumerate(similarity[0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6c575bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.9999999999999992),\n",
       " (1, 0.25185312095618806),\n",
       " (2, 0.2971343316473775),\n",
       " (3, 0.2896644470588556),\n",
       " (4, 0.4841729217397509),\n",
       " (5, 0.4889305281411559),\n",
       " (6, 0.3233768011073225),\n",
       " (7, 0.16317757411870815),\n",
       " (8, 0.22914872735609937),\n",
       " (9, 0.11821975001871085),\n",
       " (10, 0.19577891329348887),\n",
       " (11, 0.18109008374872884),\n",
       " (12, 0.12132134845448853),\n",
       " (13, 0.2816407682838141),\n",
       " (14, 0.36675858271491507),\n",
       " (15, 0.34751844141069566),\n",
       " (16, 0.432551985045844),\n",
       " (17, 0.07946412708792366),\n",
       " (18, 0.17643736784973774),\n",
       " (19, 0.23676940973827915),\n",
       " (20, 0.20385147273340484),\n",
       " (21, 0.44565946824160263),\n",
       " (22, 0.2953132128614086),\n",
       " (23, 0.3754965254665443),\n",
       " (24, 0.40378692326057697),\n",
       " (25, 0.11025972450786747),\n",
       " (26, 0.3817747490490337),\n",
       " (27, 0.2259532082548843),\n",
       " (28, 0.2385475779358538),\n",
       " (29, 0.16967815688779947),\n",
       " (30, 0.36037579676924403),\n",
       " (31, 0.2452968292875168),\n",
       " (32, 0.2314749761973694),\n",
       " (33, 0.15092843638847556),\n",
       " (34, 0.49483508245419355),\n",
       " (35, 0.2269765166454505),\n",
       " (36, 0.2545791896969659),\n",
       " (37, 0.2714133377136446),\n",
       " (38, 0.40212916031540086),\n",
       " (39, 0.18454128438730447),\n",
       " (40, 0.20054491868446783),\n",
       " (41, 0.18888463352247983),\n",
       " (42, 0.2215169572687885),\n",
       " (43, 0.1185771121489574),\n",
       " (44, 0.2271007349648593),\n",
       " (45, 0.2264254202814514),\n",
       " (46, 0.3460908000948943),\n",
       " (47, 0.22866192894140108),\n",
       " (48, 0.21547727280024168),\n",
       " (49, 0.20916732818802053),\n",
       " (50, 0.4436223687959182),\n",
       " (51, 0.37579960829004533),\n",
       " (52, 0.20124541464402118),\n",
       " (53, 0.17587552253102642),\n",
       " (54, 0.08948378753143853),\n",
       " (55, 0.2153061512268651),\n",
       " (56, 0.20373698995242664),\n",
       " (57, 0.36339101830306375),\n",
       " (58, 0.30720694488501865),\n",
       " (59, 0.24778144220007708),\n",
       " (60, 0.3539841610813113),\n",
       " (61, 0.32540223476347957),\n",
       " (62, 0.4738906967958717),\n",
       " (63, 0.16204449445380512),\n",
       " (64, 0.2672083764699308),\n",
       " (65, 0.5280388633735559),\n",
       " (66, 0.20675594988898),\n",
       " (67, 0.19130552880184945),\n",
       " (68, 0.0914837027176904),\n",
       " (69, 0.15256789667297058),\n",
       " (70, 0.22562854405797866),\n",
       " (71, 0.14452928104771287),\n",
       " (72, 0.20080868345129857),\n",
       " (73, 0.12014675253284741),\n",
       " (74, 0.4450463215500241),\n",
       " (75, 0.46448576860477253),\n",
       " (76, 0.17606918952854683),\n",
       " (77, 0.24297932936221284),\n",
       " (78, 0.1533743265993277),\n",
       " (79, 0.08689353925562975),\n",
       " (80, 0.11952191563285229),\n",
       " (81, 0.23897854972349766),\n",
       " (82, 0.27019495920339964),\n",
       " (83, 0.25901759501397464),\n",
       " (84, 0.12306703967668262),\n",
       " (85, 0.1505454609156428),\n",
       " (86, 0.08675939131316839),\n",
       " (87, 0.5216431595512738),\n",
       " (88, 0.10311743761869809),\n",
       " (89, 0.23280062238578672),\n",
       " (90, 0.1930622522399708),\n",
       " (91, 0.3552588907113322),\n",
       " (92, 0.10843608241459293),\n",
       " (93, 0.1407023804073855),\n",
       " (94, 0.25192647332231455),\n",
       " (95, 0.23686085035770768),\n",
       " (96, 0.16120363622582662),\n",
       " (97, 0.12629954441345467),\n",
       " (98, 0.1823329440671199),\n",
       " (99, 0.285201260906574),\n",
       " (100, 0.18275025338176107),\n",
       " (101, 0.06512539375216767),\n",
       " (102, 0.21389931645908902),\n",
       " (103, 0.30695158374539655),\n",
       " (104, 0.29779327983172643),\n",
       " (105, 0.18900664493048286),\n",
       " (106, 0.30144956384225946),\n",
       " (107, 0.40407700619033493),\n",
       " (108, 0.16614772646256845),\n",
       " (109, 0.4461145183591337),\n",
       " (110, 0.29890008516149114),\n",
       " (111, 0.3745096579410736),\n",
       " (112, 0.18911508870837093),\n",
       " (113, 0.30353216351685114),\n",
       " (114, 0.1535895509900086),\n",
       " (115, 0.4166746821847105),\n",
       " (116, 0.2534618032273321),\n",
       " (117, 0.21894785362459002),\n",
       " (118, 0.4456573541024883),\n",
       " (119, 0.3647824462781692),\n",
       " (120, 0.07136708908661078),\n",
       " (121, 0.15182188178971184),\n",
       " (122, 0.23509306675926184),\n",
       " (123, 0.20215428104998806),\n",
       " (124, 0.3267146596727171),\n",
       " (125, 0.2276844960966626),\n",
       " (126, 0.17658996275042219),\n",
       " (127, 0.43613027703368396),\n",
       " (128, 0.2081272055166271),\n",
       " (129, 0.13198381097871903),\n",
       " (130, 0.1882692393204421)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a47a31f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(65, 0.5280388633735559),\n",
       " (87, 0.5216431595512738),\n",
       " (34, 0.49483508245419355),\n",
       " (5, 0.4889305281411559),\n",
       " (4, 0.4841729217397509)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(enumerate(similarity[0])),reverse=True,key=lambda x:x[1])[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f9a8de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    movie_index=new_df[new_df['title']==movie].index[0]\n",
    "    distances=similarity[movie_index]\n",
    "    movies_list=sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:6]\n",
    "    \n",
    "    for i in movies_list:\n",
    "        print(new_df.iloc[i[0]].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "693ef24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical Image Segmentation using Convolutional Neural Networks\n",
      "Medical Image Segmentation using Convolutional Neural Networks\n",
      "Medical Image Analysis for Disease Diagnosis and Prognosis\n",
      "Deep Learning Models for Medical Image Analysis\n",
      "Medical Image Segmentation for Organs at Risk in Radiation Therapy\n"
     ]
    }
   ],
   "source": [
    "recommend('Semantic Segmentation for Medical Image Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "49f01ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis for Social Media Data\n",
      "Fraud Detection System using Machine Learning\n",
      "Object Detection in Satellite Images using Deep Learning\n",
      "Automated Text Summarization with Deep Learning\n",
      "Traffic Flow Prediction using Deep Learning\n"
     ]
    }
   ],
   "source": [
    "recommend('Emotion Recognition from Text using Deep Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3122d197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrusion Detection System using Machine Learning\n",
      "Anomaly Detection in Cyber-Physical Systems using Machine Learning\n",
      "Anomaly Detection in Time Series Data with Deep Learning\n",
      "Fraud Detection System using Machine Learning\n",
      "Traffic Flow Prediction using Deep Learning\n"
     ]
    }
   ],
   "source": [
    "recommend(\"Anomaly Detection in Network Traffic using Machine Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482166b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
